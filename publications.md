---
layout: page
permalink: /publications/index.html #/publications.html
title: Publications
---

# Publications

2&nbsp; ***ICCV*** &nbsp;&nbsp;&nbsp;1&nbsp; ***ECCV*** &nbsp;&nbsp;&nbsp;4&nbsp; ***ACM MM*** &nbsp;&nbsp;&nbsp;1&nbsp; ***CVPRW*** &nbsp;&nbsp;&nbsp;2&nbsp; ***ICASSP*** &nbsp;&nbsp;&nbsp;3&nbsp; ***Arxiv*** 

<!-- =================================================================================== -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="margin:5px;padding:5px;width:35%;max-width:90%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/udrs2former.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
          <papertitle>
            <strong>
              Sparse Sampling Transformer with Uncertainty-Driven Ranking for Unified Removal of Raindrops and Rain Streaks
            </strong>
          </papertitle>
          <br>
          <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Jinbin Bai, Jun Shi, Erkang Chen, Lei Zhu<sup>✉️</sup>.
          <br>  
          <em>International Conference on Computer Vision <strong>(ICCV)</strong></em>, 2023
          <br>
          <a href="Ephemeral182.github.io">[Paper]</a>
          <a href="Ephemeral182.github.io">[Code]</a>
      </td>
    </tr>

---

 <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
          <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/AWRCP_framework.jpg" alt="dise"> 
        </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
        Adverse Weather Removal with Codebook Priors
        </strong>
        </papertitle>
        <br>
        Tian Ye*,<strong><u>Sixiang Chen*</u></strong>, Jinbin Bai, Jun Shi, Chenghao Xue, Jingjia Jiang, Junjie Yin, Erkang Chen, Yun Liu<sup>✉️</sup>.
        <br>  
        <em>International Conference on Computer Vision <strong>(ICCV)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>

      

  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/Uncertainty_MM.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Uncertainty-Driven Dynamic Degradation Perceiving and Background Modeling for Efficient Single Image Desnowing
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Chenghao Xue*, Haoyu Chen, Yun Liu, Erkang Chen, Lei Zhu<sup>✉️</sup>.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/cpl.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          CPLFormer: Cross-scale Prototype Learning Transformer for Image Snow Removal
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Yun Liu, Jinbin Bai, Haoyu Chen, Yunlong Lin, Jun Shi, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/video.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Sequential Affinity Learning for Video Restoration
        </strong>
        </papertitle>
        <br>
        Tian Ye*,<strong><u>Sixiang Chen*</u></strong>, Yun Liu<sup>✉️</sup>, Wenhao Chai, Jinbin Bai, Wenbin Zou, Yunchen Zhang, jiang mingchao, Erkang Chen, Chenghao Xue.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="Ephemeral182.github.io">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/Nightformer.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          NightHazeFormer: Single Nighttime Haze Removal Using Prior Query Transformer
        </strong>
        </papertitle>
        <br>
        Yun Liu, Zhongsheng Yan, <strong><u>Sixiang Chen</u><sup>✉️</sup></strong>, Tian Ye<sup>✉️</sup>, Wenqi Ren, Erkang Chen.
        <br>  
        <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023
        <br>
        <a href="http://export.arxiv.org/abs/2305.09533#:~:text=propose%20an%20end-to-end%20transformer-based%20framework%20for%20nighttime%20haze,we%20introduce%20two%20powerful%20priors%20into%20the%20transformer">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/BMVC.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Five A+ Network: You Only Need 9K Parameters for Underwater Image Enhancement
        </strong>
        </papertitle>
        <br>
        Jingxia Jiang*, Tian Ye*, Jinbin Bai*, <strong><u>Sixiang Chen</u></strong>, Wenhao Chai, Jun Shi, Yun Liu, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>Arxiv (Under review)</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2305.08824#:~:text=In%20this%20work%2C%20we%20propose%20the%20Five%20A,The%20FA%20Net%20employs%20a%20two-stage%20enhancement%20structure.">[Paper]</a>
        <a href="https://github.com/Owen718/FiveAPlus-Network">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/dehrformer_00.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          DEHRFormer: Real-time Transformer for Depth Estimation and Haze Removal from Varicolored Haze Scenes
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Jun Shi, Yun Liu, JingXia Jiang, Erkang Chen, Peng Chen<sup>✉️</sup>.
        <br>  
        <em>International Conference on Acoustics, Speech, and Signal Processing <strong>(ICASSP)</strong></em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/10096828">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/MSP-Former_00.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Yun Liu, Taodong Liao, Jingxia Jiang, Erkang Chen, Peng Chen<sup>✉️</sup>.
        <br>  
        <em>International Conference on Acoustics, Speech, and Signal Processing <strong>(ICASSP)</strong></em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/10095605">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/snowformer.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          SnowFormer: Context Interaction Transformer with Scale-awareness for Single Image Desnowing
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Yun Liu, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>Arxiv (Under review)</em>, 2022
        <br>
        <a href="https://arxiv.org/abs/2208.09703#:~:text=SnowFormer%3A%20Context%20Interaction%20Transformer%20with%20Scale-awareness%20for%20Single,image%20desnowing%20is%20a%20challenging%20image%20restoration%20task.">[Paper]</a>
        <a href="https://github.com/Ephemeral182/SnowFormer">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/ACCV.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Towards Real-time High-Definition Image Snow Removal: Efficient Pyramid Network with Asymmetrical Encoder-decoder Architecture
        </strong>
        </papertitle>
        <br>
        Tian Ye*, <strong><u>Sixiang Chen*</u></strong>, Yun Liu, Yi Ye, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>Asian Conference on Computer Vision <strong>(ACCV)</strong></em>, 2022
        <br>
        <a href="Ephemeral182.github.io">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/dualformer.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Dual-former: Hybrid Self-attention Transformer for
          Efficient Image Restoration
        </strong>
        </papertitle>
        <br>
        <strong><u>Sixiang Chen*</u></strong>, Tian Ye*, Yun Liu, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>Arxiv (Under review)</em>, 2022
        <br>
        <a href="https://www.semanticscholar.org/paper/Dual-former%3A-Hybrid-Self-attention-Transformer-for-Chen-Ye/6eef8436384da63d4bb400e5a39a3be1b65d07ab#:~:text=Dual-former%20is%20presented%20whose%20critical%20insight%20is%20to,achieves%20superior%20performance%20on%20multiple%20image%20restoration%20tasks.">[Paper]</a>
        <a href="Ephemeral182.github.io">[Code]</a>
      </td>
      </tr>



  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/ECCV.png" alt="dise"> 
      </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Perceiving and Modeling Density for Image Dehazing
        </strong>
        </papertitle>
        <br>
        Tian Ye*, Mingchao Jiang*, Yunchen Zhang*, Liang Chen, Yun Liu, <strong><u>Sixiang Chen</u></strong>, Erkang Chen<sup>✉️</sup>.
        <br>  
        <em>European Conference on Computer Vision <strong>(ECCV Oral)</strong></em>, 2022
        <br>
        <a href="https://link.springer.com/chapter/10.1007/978-3-031-19800-7_8">[Paper]</a>
        <a href="https://github.com/Owen718/ECCV22-Perceiving-and-Modeling-Density-for-Image-Dehazing">[Code]</a>
      </td>
      </tr>


  <tr>
        <td style="margin:5px;padding:5px;width:35%;max-width:40%" align="center" class="image-wrapper">
        <img style="margin:1px;padding-right:20px;width:100%;max-width:100%" src="https://ephemeral182.github.io/images/CVPRW.png" alt="dise"> 
        </td>
      <td width="75%" valign="center" class="text-wrapper"> 
        <papertitle>
        <strong>
          Underwater Light Field Retention: Neural Rendering for Underwater Imaging
        </strong>
        </papertitle>
        <br>
        Tian Ye*, <strong><u>Sixiang Chen*</u></strong>, Yun Liu, Yi Ye, Erkang Chen<sup>✉️</sup>, Yuche Li.
        <br>  
        <em>Conference on Computer Vision and Pattern Recognition Workshop <strong>(CVPRW)</strong></em>, 2022
        <br>
        <a href="https://ieeexplore.ieee.org/document/9857150">[Paper]</a>
        <a href="https://github.com/Ephemeral182/UWNR">[Code]</a>
      </td>
      </tr>
  </tbody>
</table>

<!-- =================================================================================== -->



---


